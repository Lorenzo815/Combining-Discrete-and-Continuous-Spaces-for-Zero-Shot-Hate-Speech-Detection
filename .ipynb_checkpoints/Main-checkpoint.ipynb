{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2dd09e77-3c26-48b6-b685-5d87a12ad38b",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "97f8416c-2fcf-4f78-b128-4e2868c86c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t\n",
    "from transformers import pipeline, AutoModelForSequenceClassification, AutoTokenizer\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae11a51-592a-46da-bb9b-9ee1c35991a0",
   "metadata": {},
   "source": [
    "# Load Pretrained Roberta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7e3625c4-5e20-4849-bce4-137003efbf71",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_name = 'roberta-large-mnli'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "43e32f62-90dc-4842-b67b-b78116f2d357",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ab803a46f31467fb20f2f6fb10491b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.43G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lorenzo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\huggingface_hub\\file_download.py:127: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Lorenzo\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Some weights of the model checkpoint at roberta-large-mnli were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ae0d2a92ac0459ea583a463cee19b9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e66a59424d34b55a92b26da14c863d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a00a8d02a1624ce0925f668a44dfa663",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(m_name, num_labels=3).cuda()\n",
    "tokenizer = AutoTokenizer.from_pretrained(m_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58cf0bd7-7399-4c5c-821b-acc5eea7d0e7",
   "metadata": {},
   "source": [
    "# Create hypothesis vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0791df64-f50b-418d-9840-1f8a4fada693",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pretrained hypothesis\n",
    "full_optimized = t.load(\"VIRTUAL_TOKENS.pt\").detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "de7fa32a-f8df-4b09-b4d5-f76ad47edfcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "hateful_or_effensive = tokenizer.encode(\"this sentence contains hateful entries or offensive language\", add_special_tokens=False, return_tensors=\"pt\")\n",
    "hateful_or_effensive = model.cuda().base_model.embeddings.word_embeddings(hateful_or_effensive.cuda()).reshape([-1, 1024])\n",
    "\n",
    "# Insert hateful optimized token\n",
    "hateful_or_effensive[3] = full_optimized[3]\n",
    "# Insert or optimized token\n",
    "hateful_or_effensive[5] = full_optimized[5]\n",
    "# Insert offensive optimized token\n",
    "hateful_or_effensive[6] = full_optimized[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ea116851-921f-496b-8d16-0fa7fbf08e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard hypothesis\n",
    "pure_hypothesis1 = tokenizer.encode(\"this sentence contains hateful entries or offensive language\", add_special_tokens=False, return_tensors=\"pt\")\n",
    "pure_hypothesis1 = model.cuda().base_model.embeddings.word_embeddings(pure_hypothesis1.cuda()).reshape([-1, 1024])\n",
    "\n",
    "pure_hypothesis2 = tokenizer.encode(\"this sentence contains offensive language\", add_special_tokens=False, return_tensors=\"pt\")\n",
    "pure_hypothesis2 = model.cuda().base_model.embeddings.word_embeddings(pure_hypothesis2.cuda()).reshape([-1,1024])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e680e19-190f-4a54-ac36-3a7f57c027b6",
   "metadata": {},
   "source": [
    "# Custom create entailment calcualtion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "37a54c50-b8fd-47c9-a75b-86d8a9691b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "sep_token_emb = model.cuda().base_model.embeddings.word_embeddings(t.tensor(tokenizer.sep_token_id).int().cuda())\n",
    "\n",
    "def comput_entailment(test,v_tokens_emb):\n",
    "    \n",
    "    input = t.tensor(tokenizer(test)[\"input_ids\"]).cuda()\n",
    "\n",
    "    add_virtual_tokens = t.cat([\n",
    "            sep_token_emb.reshape(1,-1).cuda(),\n",
    "            v_tokens_emb,\n",
    "            sep_token_emb.reshape(1,-1).cuda()\n",
    "        ],dim=0)\n",
    "\n",
    "    words_emb = model.base_model.embeddings.word_embeddings(input)\n",
    "\n",
    "    model_input_emb = t.cat([\n",
    "        words_emb,\n",
    "        add_virtual_tokens\n",
    "    ],dim=0)\n",
    "    \n",
    "    model_res_prev = model(inputs_embeds=model_input_emb.reshape(1,-1,1024)).logits.detach().cpu()\n",
    "    return t.nn.functional.softmax(model_res_prev, dim=1).reshape(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3c3242-2903-417f-84bf-fd22edabe29c",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "94ba0d7c-352c-4bc9-87bd-9cd21c5ec309",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_res = []\n",
    "\n",
    "test_sentence = \"Latinos are here just to steal our jobs\"\n",
    "\n",
    "for hypo in zip([full_optimized, \n",
    "                 hateful_or_effensive,\n",
    "                 pure_hypothesis1, \n",
    "                 pure_hypothesis2],\n",
    "                [\"full_optimized\",\n",
    "                 \"this sentence contains [Tuned HATEFUL] entries [Tuned OR] [Tuned OFFENSIVE] language\",\n",
    "                 \"this sentence contains hateful entries or offensive language\",\n",
    "                \"this sentence contains offensive language\"]):\n",
    "    \n",
    "    save_res.append({\n",
    "    \"test_sentence\": test_sentence,\n",
    "    \"hypothesis\":hypo[1],\n",
    "    \"entailmente result (chance of being hateful)\":float(comput_entailment(test_sentence, hypo[0])[-1]),\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "2ab5b814-ce7f-499e-99e6-4b5a51a00cef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_sentence</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>entailmente result (chance of being hateful)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Latinos are here just to steal our jobs</td>\n",
       "      <td>full_optimized</td>\n",
       "      <td>0.978846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Latinos are here just to steal our jobs</td>\n",
       "      <td>this sentence contains [Tuned HATEFUL] entries...</td>\n",
       "      <td>0.877184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Latinos are here just to steal our jobs</td>\n",
       "      <td>this sentence contains hateful entries or offe...</td>\n",
       "      <td>0.174813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Latinos are here just to steal our jobs</td>\n",
       "      <td>this sentence contains offensive language</td>\n",
       "      <td>0.098323</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             test_sentence  \\\n",
       "0  Latinos are here just to steal our jobs   \n",
       "1  Latinos are here just to steal our jobs   \n",
       "2  Latinos are here just to steal our jobs   \n",
       "3  Latinos are here just to steal our jobs   \n",
       "\n",
       "                                          hypothesis  \\\n",
       "0                                     full_optimized   \n",
       "1  this sentence contains [Tuned HATEFUL] entries...   \n",
       "2  this sentence contains hateful entries or offe...   \n",
       "3          this sentence contains offensive language   \n",
       "\n",
       "   entailmente result (chance of being hateful)  \n",
       "0                                      0.978846  \n",
       "1                                      0.877184  \n",
       "2                                      0.174813  \n",
       "3                                      0.098323  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(save_res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
